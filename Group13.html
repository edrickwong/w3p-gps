<!doctype html>

<!--[if lt IE 7 ]> <html class="ie ie6 no-js" lang="en"> <![endif]-->
<!--[if IE 7 ]>    <html class="ie ie7 no-js" lang="en"> <![endif]-->
<!--[if IE 8 ]>    <html class="ie ie8 no-js" lang="en"> <![endif]-->
<!--[if IE 9 ]>    <html class="ie ie9 no-js" lang="en"> <![endif]-->
<!--[if gt IE 9]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->
<!-- the "no-js" class is for Modernizr. -->

<head id="SYDE Capstone Projects" data-template-set="html5-reset">

  <meta charset="utf-8">
  <META HTTP-EQUIV="Pragma" CONTENT="no-cache">
  <META HTTP-EQUIV="Expires" CONTENT="-1">

  <!-- Always force latest IE rendering engine (even in intranet) & Chrome Frame -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <title>SYDE Capstone Projects 2018</title>
  <meta name="keywords" CONTENT="design, engineering, systems">
  <!-- Google will often use this as its description of your page/site. Make it good. -->

  <meta name="author" content="SYDE">
  <meta name="Copyright" content="SYDE 2018. All Rights Reserved.">

  <!-- Dublin Core Metadata : http://dublincore.org/ -->
  <meta name="DC.title" content="Systems">
  <meta name="DC.subject" content="design">
  <meta name="DC.creator" content="SYDE">

  <!--  Mobile Viewport Fix
                                                     j.mp/mobileviewport & davidbcalhoun.com/2010/viewport-metatag
                                                     device-width : Occupy full width of the screen in its current orientation
                                                     initial-scale = 1.0 retains dimensions instead of zooming out if page height > device height
                                                     maximum-scale = 1.0 retains dimensions instead of zooming in if page width < device width
                                                     -->
  <!-- Uncomment to use — use thoughtfully!
                                                     <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
                                                     -->

  <link rel="shortcut icon" href="_/img/favicon.ico">
  <!-- This is the traditional favicon.
                                                         - size: 16x16 or 32x32
                                                         - transparency is OK
                                                         - see wikipedia for info on browser support: http://mky.be/favicon/ -->

  <link rel="apple-touch-icon" href="_/img/apple-touch-icon.png">
  <!-- The is the icon for iOS's Web Clip.
                                                             - size: 57x57 for older iPhones, 72x72 for iPads, 114x114 for iPhone4's retina display (IMHO, just go ahead and use the biggest one)
                                                             - To prevent iOS from applying its styles to the icon name it thusly: apple-touch-icon-precomposed.png
                                                             - Transparency is not recommended (iOS will put a black BG behind the icon) -->

  <!-- CSS: screen, mobile & print are all in the same file -->
  <link rel="stylesheet" href="_/css/style.css">

  <!-- all our JS is at the bottom of the page, except for Modernizr. -->
  <script src="_/js/modernizr-1.7.min.js"></script>

</head>

<body>

  <wrapper>

    <header>
      <img id='display' align='right' src='_/img/UW.png' alt='UWaterloo Logo' width='200'>
      <h3>Systems Design Engineering Capstone Projects 2018</h2><br>
                <h1>Group #13: w三p</h1>
                <h2>Anshuman Patnaik, Linda Wang, Edrick Wong, Justin Wong</h2>
            </header>
            <mainbody>
              <bodytext>
                <h3>Situation of Concern</h3><br>
      <p1> The project focuses on improving the kitchen experience for visually impaired individuals. Specifically, the target users are blind individuals who once had vision but are now visually impaired. The target group lives in an average North American household shared with other tenants. The household consists of a normal kitchen and the users dislike common aids that would label them as blind individuals .The proposed solution uses existing technologies including a USB camera, Google Home, Google Assistant, and Tensorflow framework. In a nutshell, a user can ask Google Assistant, an interactive intelligent assistive system, for the location of an object. Google will fetch visual information from the camera, send it to a cloud-based service involving object recognition and location determination via a trained object detection model. Finally, inquiries are surfaced back to the user via the Google Home as audio feedback. All the technology needed to capture visual information, recognize and determine objects via computer vision, interpret speech commands, etc. is available but will be integrated and packaged together into a natural and empowering kitchen experience for the user.
      </p1><br><br><br>

      <img src='_/img/SystemDiagram.png' alt='System Diagram' width='1000'>
      <p2>System Diagram</p2><br><br><br>

      <h3>Why Does This Matter?</h3><br>
      <p1> Fundamentally, MIRU is trying to create a social impact for visually impaired individuals. The goal of MIRU is to bridge the interaction between sighted friends and families and the visually impaired individual. A positive impact of MIRU is that it provides the visually impaired individual an autonomous level of situational and environmental awareness that was not available to them before, and at the same time, leverages a platform that can be used by others for other purposes. As well, there are currently no general solutions to this problem; it is an area that has not been thoroughly explored from the perspective of the user.
      </p1><br><br><br>

      <img src='_/img/FunctionalDiagram.png' alt='Fucntional Diagram of Solution' width='1000'>
      <p2>Functional Diagram</p2><br><br><br>

      <h3>Designed Solution</h3><br>
      <p1> The designed solution consists of a Google Home as the user interface and an    SSD Mobile-net object detection framework as the backend. The Google Home accepts a user’s speech request, converts the speech to text, and extracts the specified object of interest and intent from the request. If Google Home does not recognize the object it will respond to the user at this point. Otherwise, the object and intent is passed to the backend object detector component. The object detection framework analyzes the frame passed by the camera and returns a list of detected objects, bounding boxes for each of the boxes and their associated probabilities. These results from the neural net are used in conjunction with information about reference objects to build an allocentric response for the user. This response is passed back to the Google Home that relays an audio response back to the user.
      </p1><br><br><br>

      <img src='_/img/Prototype.png' alt='Prototyped Solution' width='1000'>
      <p2>Prototype</p2><br><br><br>

      <img src='_/img/WhateverYouWant.png' alt='Change this alt-text' width='1000'>
      <p2>Change This Title Appropriately</p2><br><br><br>
      </mainbody>

      <footer>
        <br>
        <p>Systems Design Engineering Capstone Projects 2018</p>
      </footer>

  </wrapper>

  <!-- here comes the javascript -->

  <!-- Grab Google CDN's jQuery. fall back to local if necessary -->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
  <script>
    window.jQuery || document.write("<script src='_/js/jquery-1.5.1.min.js'>\x3C/script>")
  </script>

  <!-- this is where we put our custom functions -->
  <script src="_/js/functions.js"></script>

</body>

</html>
